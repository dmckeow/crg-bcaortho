nextflow.enable.dsl = 2

params {
    samplesheet = 'example_data/samplesheet.csv'
    search_params = 'example_data/samplesheet.csv'
    outdir = 'results/example'
    runName = 'example_data'
    mcl_inflation = 2.5

    run {
        prefilter_proteomes = true
        init_ortho_orthofinder = true
    }
    // max resources used for attempting retries
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'
}

includeConfig 'conf/base.config'
includeConfig 'conf/modules.config'

// Profiles for resource, env, container management

profiles {
    local {
        process.executor = 'local'
        singularity.enabled = true
        singularity.pullout = '1h'
        conda.enabled = true
        conda.useMamba = true
        process {
            cpus = 8
            memory = 30.GB
        }
    }
    slurm {
        includeConfig 'conf/slurm.config'
        
    } 

}

// Management stuff
manifest {
    name = 'crg-bcaortho'
    description = 'pipeline'
    author = 'Dean Mckeown'
    version = '1.0.0'
    nextflowVersion = '24.10.2'
    homePage = 'https://github.com/dmckeow/crg-bcaortho'
}

// Resource usage reports

workflow.onComplete = {
    println "Pipeline completed at: $workflow.complete"
    println "Execution status: ${ workflow.success ? 'OK' : 'failed' }"
    println "Pipeline parameters:"
    params.each { k, v ->
        println "  $k: $v"
    }
}

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
report {
    enabled = true
    file = "${params.outdir}/pipeline_info/${trace_timestamp}_report.html"
    showSkipped = false
    showTaskCacheInfo = false
    showTaskResources = true
    showTaskResourcesPercentage = true
}

timeline {
    enabled = true
    file = "${params.outdir}/pipeline_info/${trace_timestamp}_timeline.html"
}

trace {
    enabled = true
    file = "${params.outdir}/pipeline_info/${trace_timestamp}_trace.tsv"
    fields = 'task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes'
}

dag {
    enabled = true
    file = "${params.outdir}/pipeline_info/${trace_timestamp}_dag.png"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}